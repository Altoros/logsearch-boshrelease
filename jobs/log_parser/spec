---
name: log_parser
packages: 
- logstash
- java7
templates:
  bin/log_parser_ctl: bin/log_parser_ctl
  bin/monit_debugger: bin/monit_debugger
  data/properties.sh.erb: data/properties.sh
  helpers/ctl_setup.sh: helpers/ctl_setup.sh
  helpers/ctl_utils.sh: helpers/ctl_utils.sh
  config/input_redis_and_output_elasticsearch.conf.erb: config/input_redis_and_output_elasticsearch.conf
  config/filters_pre.conf.erb: config/filters_pre.conf
  config/filters_post.conf.erb: config/filters_post.conf
  config/filters_default.conf: config/filters_default.conf
  config/filters_override.conf.erb: config/filters_override.conf
properties:
  logstash_parser.debug:
    description: Debug level logging
    default: false
  logstash_parser.message_max_size:
    description: "Maximum log message length.  Anything larger is truncated (TODO: move this to ingestor?)"
    default: 1048576
  logstash_parser.filters:
    description: "The configuration to embed into the logstash filters section"
    default: ''
  logstash_parser.workers:
    description: "The number of worker threads that logstash should use (default: auto = one per CPU)"
    default: auto
  logstash_parser.idle_flush_time:
    description: "How frequently to flush events if the output queue is not full."

  kafka.zookeeper:
    description: "An array of host:port values to Zookeeper hosts"
  kafka.topic:
    description: "The logstash topic being used"
    default: "logstash"

  elasticsearch.host:
    description: IP / DNS of elasticsearch http endpoint
  elasticsearch.port:
    description: Port of elasticsearch http endpoint
    default: 9200
  elasticsearch.flush_size:
    description: Redis queue flush size
    default: 100

  redis.host: 
    description: Redis host of queue
  redis.port: 
    description: Redis port of queue
    default: 6379
  redis.key: 
    description: Name of queue to pull messages from
    default: logstash

